"""#### Importting library ###"""

import numpy
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, LSTM, Bidirectional
from tensorflow.keras.layers import Embedding, Reshape
from tensorflow.keras.layers import Flatten,Conv1D, GlobalMaxPooling1D,MaxPooling1D,GlobalAveragePooling1D
import tensorflow as tf
from tensorflow.keras import layers


maxlen_pad = 30000
EPOCHS = None
Batch_size = None
"""################ loading from file #################"""

print("Loading Data")
data = numpy.load("Dataset 2.0 (completed)/(20000xunknow)(1D Data Section Extraction-padded).npz")
X_train= data['X_train']
y_train= data['y_train']
X_test = data['X_test']
y_test = data['y_test']
print("Done")

print("Training Dataset Size : ", X_train.shape)      
print("Test Dataset Size : ", X_test.shape)
# y_train_onehot = tf.keras.utils.to_categorical(y_train)
# y_test_onehot = tf.keras.utils.to_categorical(y_test)
# print(y_train_onehot.shape)
# print(y_test_onehot.shape)

"""############################  model #####################################"""


EPOCHS = 10
Batch_size = 120
def create_model1():
    print('Build model...')
    
    model = Sequential()
    n_timesteps, n_features, n_input = int(30000 / 4), 4, maxlen_pad 
    model.add(Reshape((n_timesteps, n_features), input_shape=(n_input,)))
    model.add(Dropout(0.1))
    # A Convolution1D layer
    model.add(Conv1D(128,#filters (number of features))
                      32,#kernel size
                      padding='valid',
                      activation='relu',
                      strides=1))
    model.add(Dropout(0.1))
    model.add(layers.LSTM(64))
    model.add(layers.Dense(1, activation='sigmoid'))
    return model 

def create_model3():
    print('Build model...')
    
    model = Sequential()
    n_timesteps, n_features, n_input = int(30000 / 4), 4, maxlen_pad 
    model.add(Reshape((n_timesteps, n_features), input_shape=(n_input,)))
    model.add(Dropout(0.5))
    # A Convolution1D layer
    model.add(Conv1D(128,#filters (number of features))
                      8,#kernel size
                      padding='valid',
                      activation='relu',
                      strides=1))
    model.add(Conv1D(128,#filters (number of features))
                      8,#kernel size
                      padding='valid',
                      activation='relu',
                      strides=1))
    model.add(Dropout(0.5))
    model.add(MaxPooling1D(8))
    model.add(layers.LSTM(8))
    model.add(layers.Dense(1, activation='sigmoid'))
    return model 


def create_model2():
    print('Build model...')
    model = Sequential()
    # model.add(Reshape((maxlen_pad, 1), input_shape=(maxlen_pad,)))
    # model.add(Dropout(0.2))
    model.add(Embedding(256, # the largest integer in the input should not be higher then 255
                        64, # random value which serves as the vector space that each word will be embedded as. 
                        input_length=maxlen_pad))
    model.add(Dropout(0.5))
    # A Convolution1D layer
    model.add(Conv1D(64,#filters
                      8,#kernel size
                      padding='valid',
                      activation='relu',
                      strides=1))
    model.add(Dropout(0.5))
    model.add(Bidirectional(LSTM(64)))
    model.add(layers.Dense(1, activation='sigmoid'))
    return model 

model = create_model1()
model.summary()

model.compile(loss='binary_crossentropy', 
              optimizer='adam', metrics=['acc'])   

history = model.fit(X_train, y_train, 
                    batch_size= Batch_size, epochs=EPOCHS, 
                    validation_data=(X_test, y_test))











"""######################## Evaluation ######################"""
#Loss
 

epochs = numpy.arange(1, EPOCHS + 1)
plt.plot(epochs, history.history['loss'],label = "Train_loss")
plt.plot(epochs, history.history['val_loss'], label = "Valid_loss" )
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

#Accuracy
plt.plot(epochs, history.history['acc'],label = "Train_acc")
plt.plot(epochs, history.history['val_acc'],label = "valid_Acc")
plt.legend()
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.show()

#Evaluating
train_loss, train_acc = model.evaluate(X_train, y_train,verbose = 0)
# valid_loss, valid_acc = model.evaluate(X_valid_std, y_valid_onehot,verbose = 0)
test_loss, test_acc = model.evaluate(X_test, y_test,verbose = 0)
print("On Training Set: (loss,acc): %.5f %.5f" % (train_loss,train_acc))
# print("On Validation Set: (loss,acc): ",valid_loss, valid_acc)
print("On Test Set: (loss,acc): %.5f %.5f" % (test_loss,test_acc))
# # More evaluation
# y_true = y_test
# y_pred = [np.argmax(i) for i in model.predict(X_test_std)]
# cm = confusion_matrix(y_true, y_pred)
# precision =  cm[0,0]/(cm[0,0] + cm[0,1])
# recall = cm[0,0]/(cm[0,0] + cm[1,0])
# F1score = 2 * ((precision * recall) / (precision + recall))
# #F1score = f1_score(y_true,y_pred)
# print("Precision: ", precision)
# print("Recall: ", recall)
# print("F1_Score: ", F1score)