import Lib_Import

"""######################## Evaluation ######################"""
#Getting predicted values on test dataset from model
result = model.predict(X_Test_data_norm,verbose=1)
y_pred = [numpy.argmax(i) for i in result]
y_pred = numpy.asarray(y_pred)
#calculate the true label for test dataset
y_true = []
for i in X_Test_data_norm.unbatch():
    y_true.append(numpy.argmax(i[1].numpy()))
y_true = numpy.asarray(y_true)

#find the confusion matrix
acc = accuracy_score(y_pred,y_true)

cm = confusion_matrix(y_true, y_pred)
#precision =  cm[0,0]/(cm[0,0] + cm[0,1])
#recall = cm[0,0]/(cm[0,0] + cm[1,0])
temp = precision_recall_fscore_support(y_true, y_pred, average='binary')
precision = temp[0]
recall = temp[1]
F1score = temp[2]
#F1score = f1_score(y_true, y_pred, average='weighted')
#F1score = 2 * ((precision * recall) / (precision + recall))

#Loss
# epochs = numpy.arange(1, EPOCHS + 1)
# plt.plot(epochs, history.history['loss'],label = "Train_loss")
# plt.plot(epochs, history.history['val_loss'], label = "Valid_loss" )
# plt.xlabel('epochs')
# plt.ylabel('loss')
# plt.legend()
# plt.show()

# #Accuracy
# plt.plot(epochs, history.history['accuracy'],label = "Train_acc")
# plt.plot(epochs, history.history['val_accuracy'],label = "valid_Acc")
# plt.legend()
# plt.xlabel('epochs')
# plt.ylabel('accuracy')
# plt.show()

#test_loss, binary_accuracy,categorical_accuracy  = model.evaluate(X_Test_data_norm,verbose = 1)
print(" ")
#print("On Test Set: (loss,binary_acc,categorical_acc): %.5f %.5f %.5f" % (test_loss,binary_accuracy,categorical_accuracy))
#F1score = f1_score(y_true,y_pred)
print("sklearn accuracy : {}".format(acc))
print("Precision: ", precision)
print("Recall: ", recall)
print("F1_Score: ", F1score)
print("confusion matrix:")
print("")
print(cm)

