{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "test": {
      "output": "ignore",
      "timeout": 900
     }
    },
    "colab_type": "code",
    "id": "x_3b6xx2s6B9",
    "outputId": "537ab5cf-35f1-4222-b44d-e7b327153d0a"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import functools\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import adanet\n",
    "from adanet.examples import simple_dnn\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "# The random seed to use.\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "LOG_DIR = 'AdaNetmodels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tECo5dFd4QCa"
   },
   "source": [
    "## Supply the data in TensorFlow\n",
    "\n",
    "Our first task is to supply the data in TensorFlow. Using the\n",
    "tf.estimator.Estimator covention, we will define a function that returns an\n",
    "`input_fn` which returns feature and label `Tensors`.\n",
    "\n",
    "We will also use the `tf.data.Dataset` API to feed the data into our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = (\n",
    "    tf.keras.datasets.fashion_mnist.load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 900
     }
    },
    "colab_type": "code",
    "id": "gxTAoIXwsTH7"
   },
   "outputs": [],
   "source": [
    "FEATURES_KEY = \"images\"\n",
    "\n",
    "\n",
    "def generator(images, labels):\n",
    "  \"\"\"Returns a generator that returns image-label pairs.\"\"\"\n",
    "\n",
    "  def _gen():\n",
    "    for image, label in zip(images, labels):\n",
    "      yield image, label\n",
    "\n",
    "  return _gen\n",
    "\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "  \"\"\"Preprocesses an image for an `Estimator`.\"\"\"\n",
    "  # First let's scale the pixel values to be between 0 and 1.\n",
    "  image = image / 255.\n",
    "  # Next we reshape the image so that we can apply a 2D convolution to it.\n",
    "  image = tf.reshape(image, [28, 28, 1])\n",
    "  # Finally the features need to be supplied as a dictionary.\n",
    "  features = {FEATURES_KEY: image}\n",
    "  return features, label\n",
    "\n",
    "\n",
    "def input_fn(partition, training, batch_size):\n",
    "  \"\"\"Generate an input_fn for the Estimator.\"\"\"\n",
    "\n",
    "  def _input_fn():\n",
    "    if partition == \"train\":\n",
    "      dataset = tf.data.Dataset.from_generator(\n",
    "          generator(x_train, y_train), (tf.float32, tf.int32), ((28, 28), ()))\n",
    "    elif partition == \"predict\":\n",
    "      dataset = tf.data.Dataset.from_generator(\n",
    "          generator(x_test[:10], y_test[:10]), (tf.float32, tf.int32), ((28,28), ()))\n",
    "    else:\n",
    "      dataset = tf.data.Dataset.from_generator(\n",
    "          generator(x_test, y_test), (tf.float32, tf.int32), ((28, 28), ()))\n",
    "\n",
    "    # We call repeat after shuffling, rather than before, to prevent separate\n",
    "    # epochs from blending together.\n",
    "    if training:\n",
    "        pass\n",
    "      #dataset = dataset.shuffle(10 * batch_size, seed=RANDOM_SEED).repeat()\n",
    "      #dataset = dataset.repeat()\n",
    "   \n",
    "\n",
    "    dataset = dataset.map(preprocess_image).batch(batch_size)\n",
    "    #iterator = dataset.make_one_shot_iterator()\n",
    "    #features, labels = iterator.get_next()\n",
    "    return dataset\n",
    "\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vm9yudEv5lQZ"
   },
   "source": [
    "## Establish baselines\n",
    "\n",
    "The next task should be to get somes baselines to see how our model performs on\n",
    "this dataset.\n",
    "\n",
    "Let's define some information to share with all our `tf.estimator.Estimators`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 900
     }
    },
    "colab_type": "code",
    "id": "xNwSUWh-9_Ib"
   },
   "outputs": [],
   "source": [
    "# The number of classes.\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# A `Head` instance defines the loss function and metrics for `Estimators`.\n",
    "head = tf.estimator.MultiClassHead(NUM_CLASSES)\n",
    "\n",
    "# Some `Estimators` use feature columns for understanding their input features.\n",
    "feature_columns = [\n",
    "    tf.feature_column.numeric_column(FEATURES_KEY, shape=[28, 28, 1])\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D3IE6-9vFVlg"
   },
   "source": [
    "## Define a model\n",
    "\n",
    "Creating a new search space for AdaNet to explore is straightforward. There are\n",
    "two abstract classes you need to extend:\n",
    "\n",
    "1.  `adanet.subnetwork.Builder`\n",
    "2.  `adanet.subnetwork.Generator`\n",
    "\n",
    "Similar to the tf.estimator.Estimator `model_fn`, `adanet.subnetwork.Builder`\n",
    "allows you to define your own TensorFlow graph for creating a neural network,\n",
    "and specify the training operations.\n",
    "\n",
    "Below we define one that applies a 2D convolution, max-pooling, and then a\n",
    "fully-connected layer to the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 900
     }
    },
    "colab_type": "code",
    "id": "IsYJ97tRwBkt"
   },
   "outputs": [],
   "source": [
    "class SimpleCNNBuilder_1(adanet.subnetwork.Builder):\n",
    "    \"\"\"Builds a CNN subnetwork for AdaNet.\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate, max_iteration_steps, seed):\n",
    "        self._learning_rate = learning_rate\n",
    "        self._max_iteration_steps = max_iteration_steps\n",
    "        self._seed = seed\n",
    "    \n",
    "    def build_subnetwork(self,features,logits_dimension,training,iteration_step,summary,previous_ensemble=None):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "        images = list(features.values())[0]\n",
    "\n",
    "        # Visualize some of the input images in TensorBoard.\n",
    "        summary.image(\"images\", images)\n",
    "\n",
    "        kernel_initializer = tf.keras.initializers.he_normal(seed=self._seed)\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=kernel_initializer)(\n",
    "                images)\n",
    "        x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(\n",
    "            units=64, activation=\"relu\", kernel_initializer=kernel_initializer)(\n",
    "                x)\n",
    "\n",
    "        # The `Head` passed to adanet.Estimator will apply the softmax activation.\n",
    "        logits = tf.keras.layers.Dense(\n",
    "            units=10, activation=None, kernel_initializer=kernel_initializer)(\n",
    "                x)\n",
    "\n",
    "        # Use a constant complexity measure, since all subnetworks have the same\n",
    "        # architecture and hyperparameters.\n",
    "        complexity = tf.constant(1)\n",
    "\n",
    "        return adanet.Subnetwork(\n",
    "            last_layer=x,\n",
    "            logits=logits,\n",
    "            complexity=complexity,\n",
    "            persisted_tensors={})\n",
    "    \n",
    "    def build_subnetwork_train_op(self,subnetwork,loss,var_list,labels,iteration_step,summary,previous_ensemble=None):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "\n",
    "        # Momentum optimizer with cosine learning rate decay works well with CNNs.\n",
    "        learning_rate = tf.train.cosine_decay(\n",
    "            learning_rate=self._learning_rate,\n",
    "            global_step=iteration_step,\n",
    "            decay_steps=self._max_iteration_steps)\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate, .9)\n",
    "        # NOTE: The `adanet.Estimator` increments the global step.\n",
    "        return optimizer.minimize(loss=loss, var_list=var_list)\n",
    "    \n",
    "    def build_mixture_weights_train_op(self, loss, var_list, logits, labels,iteration_step, summary):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "\n",
    "        return tf.no_op(\"mixture_weights_train_op\")\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "        return \"simple_cnn_one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNBuilder_2(adanet.subnetwork.Builder):\n",
    "    \"\"\"Builds a CNN subnetwork for AdaNet.\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate, max_iteration_steps, seed):\n",
    "        self._learning_rate = learning_rate\n",
    "        self._max_iteration_steps = max_iteration_steps\n",
    "        self._seed = seed\n",
    "    \n",
    "    def build_subnetwork(self,features,logits_dimension,training,iteration_step,summary,previous_ensemble=None):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "        images = list(features.values())[0]\n",
    "\n",
    "        # Visualize some of the input images in TensorBoard.\n",
    "        summary.image(\"images\", images)\n",
    "\n",
    "        kernel_initializer = tf.keras.initializers.he_normal(seed=self._seed)\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=kernel_initializer)(\n",
    "                images)\n",
    "        x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=kernel_initializer)(x)\n",
    "        x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(\n",
    "            units=64, activation=\"relu\", kernel_initializer=kernel_initializer)(\n",
    "                x)\n",
    "\n",
    "        # The `Head` passed to adanet.Estimator will apply the softmax activation.\n",
    "        logits = tf.keras.layers.Dense(\n",
    "            units=10, activation=None, kernel_initializer=kernel_initializer)(\n",
    "                x)\n",
    "\n",
    "        # Use a constant complexity measure, since all subnetworks have the same\n",
    "        # architecture and hyperparameters.\n",
    "        complexity = tf.constant(1)\n",
    "\n",
    "        return adanet.Subnetwork(\n",
    "            last_layer=x,\n",
    "            logits=logits,\n",
    "            complexity=complexity,\n",
    "            persisted_tensors={})\n",
    "    \n",
    "    def build_subnetwork_train_op(self,subnetwork,loss,var_list,labels,iteration_step,summary,previous_ensemble=None):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "\n",
    "        # Momentum optimizer with cosine learning rate decay works well with CNNs.\n",
    "        learning_rate = tf.train.cosine_decay(\n",
    "            learning_rate=self._learning_rate,\n",
    "            global_step=iteration_step,\n",
    "            decay_steps=self._max_iteration_steps)\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate, .9)\n",
    "        # NOTE: The `adanet.Estimator` increments the global step.\n",
    "        return optimizer.minimize(loss=loss, var_list=var_list)\n",
    "    \n",
    "    def build_mixture_weights_train_op(self, loss, var_list, logits, labels,iteration_step, summary):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "\n",
    "        return tf.no_op(\"mixture_weights_train_op\")\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "        return \"simple_cnn_two\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNBuilder_3(adanet.subnetwork.Builder):\n",
    "    \"\"\"Builds a CNN subnetwork for AdaNet.\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate, max_iteration_steps, seed):\n",
    "        self._learning_rate = learning_rate\n",
    "        self._max_iteration_steps = max_iteration_steps\n",
    "        self._seed = seed\n",
    "    \n",
    "    def build_subnetwork(self,features,logits_dimension,training,iteration_step,summary,previous_ensemble=None):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "        images = list(features.values())[0]\n",
    "\n",
    "        # Visualize some of the input images in TensorBoard.\n",
    "        summary.image(\"images\", images)\n",
    "\n",
    "        kernel_initializer = tf.keras.initializers.he_normal(seed=self._seed)\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=kernel_initializer)(\n",
    "                images)\n",
    "        x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "        x = tf.keras.layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=3,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=kernel_initializer)(x)\n",
    "        x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(\n",
    "            units=64, activation=\"relu\", kernel_initializer=kernel_initializer)(\n",
    "                x)\n",
    "        x = tf.keras.layers.Dense(\n",
    "            units=64, activation=\"relu\", kernel_initializer=kernel_initializer)(\n",
    "                x)\n",
    "\n",
    "        # The `Head` passed to adanet.Estimator will apply the softmax activation.\n",
    "        logits = tf.keras.layers.Dense(\n",
    "            units=10, activation=None, kernel_initializer=kernel_initializer)(\n",
    "                x)\n",
    "\n",
    "        # Use a constant complexity measure, since all subnetworks have the same\n",
    "        # architecture and hyperparameters.\n",
    "        complexity = tf.constant(1)\n",
    "\n",
    "        return adanet.Subnetwork(\n",
    "            last_layer=x,\n",
    "            logits=logits,\n",
    "            complexity=complexity,\n",
    "            persisted_tensors={})\n",
    "    \n",
    "    def build_subnetwork_train_op(self,subnetwork,loss,var_list,labels,iteration_step,summary,previous_ensemble=None):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "\n",
    "        # Momentum optimizer with cosine learning rate decay works well with CNNs.\n",
    "        learning_rate = tf.train.cosine_decay(\n",
    "            learning_rate=self._learning_rate,\n",
    "            global_step=iteration_step,\n",
    "            decay_steps=self._max_iteration_steps)\n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate, .9)\n",
    "        # NOTE: The `adanet.Estimator` increments the global step.\n",
    "        return optimizer.minimize(loss=loss, var_list=var_list)\n",
    "    \n",
    "    def build_mixture_weights_train_op(self, loss, var_list, logits, labels,iteration_step, summary):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "\n",
    "        return tf.no_op(\"mixture_weights_train_op\")\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"See `adanet.subnetwork.Builder`.\"\"\"\n",
    "        return \"simple_cnn_three\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFamPrZHJ5ii"
   },
   "source": [
    "Next, we extend a `adanet.subnetwork.Generator`, which defines the search\n",
    "space of candidate `SimpleCNNBuilders` to consider including the final network.\n",
    "It can create one or more at each iteration with different parameters, and the\n",
    "AdaNet algorithm will select the candidate that best improves the overall neural\n",
    "network's `adanet_loss` on the training set.\n",
    "\n",
    "The one below is very simple: it always creates the same architecture, but gives\n",
    "it a different random seed at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "test": {
      "output": "ignore",
      "timeout": 900
     }
    },
    "colab_type": "code",
    "id": "-BAnb_XGwhRy"
   },
   "outputs": [],
   "source": [
    "class SimpleCNNGenerator(adanet.subnetwork.Generator):\n",
    "  \"\"\"Generates a `SimpleCNN` at each iteration.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, learning_rate, max_iteration_steps, seed=None):\n",
    "    \"\"\"Initializes a `Generator` that builds `SimpleCNNs`.\n",
    "\n",
    "    Args:\n",
    "      learning_rate: The float learning rate to use.\n",
    "      max_iteration_steps: The number of steps per iteration.\n",
    "      seed: The random seed.\n",
    "\n",
    "    Returns:\n",
    "      An instance of `Generator`.\n",
    "    \"\"\"\n",
    "    self._seed = seed\n",
    "    self._dnn_builder_fn_1 = functools.partial(\n",
    "        SimpleCNNBuilder_1,\n",
    "        learning_rate=learning_rate,\n",
    "        max_iteration_steps=max_iteration_steps)\n",
    "    self._dnn_builder_fn_2 = functools.partial(\n",
    "        SimpleCNNBuilder_2,\n",
    "        learning_rate=learning_rate,\n",
    "        max_iteration_steps=max_iteration_steps)\n",
    "    self._dnn_builder_fn_3 = functools.partial(\n",
    "        SimpleCNNBuilder_3,\n",
    "        learning_rate=learning_rate,\n",
    "        max_iteration_steps=max_iteration_steps)\n",
    "\n",
    "  def generate_candidates(self, previous_ensemble, iteration_number,\n",
    "                          previous_ensemble_reports, all_reports):\n",
    "    \"\"\"See `adanet.subnetwork.Generator`.\"\"\"\n",
    "    seed = self._seed\n",
    "    # Change the seed according to the iteration so that each subnetwork\n",
    "    # learns something different.\n",
    "    if seed is not None:\n",
    "      seed += iteration_number\n",
    "    return [self._dnn_builder_fn_1(seed=seed)]\n",
    "#return [self._dnn_builder_fn_1(seed=seed),self._dnn_builder_fn_3(seed=seed),self._dnn_builder_fn_2(seed=seed)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sdvharsLJ1T"
   },
   "source": [
    "With these defined, we pass them into a new `adanet.Estimator`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Parameters\n",
    "LEARNING_RATE = 0.05  #@param {type:\"number\"}\n",
    "TRAIN_STEPS = 100  #@param {type:\"integer\"}\n",
    "BATCH_SIZE = 64  #@param {type:\"integer\"}\n",
    "ADANET_ITERATIONS = 1  #@param {type:\"integer\"}\n",
    "max_iteration_steps = TRAIN_STEPS // ADANET_ITERATIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting up Multiple GPU\n",
    "#strategy = tf.distribute.MirroredStrategy()\n",
    "#print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_config(experiment_name):\n",
    "  # Estimator configuration.\n",
    "  return tf.estimator.RunConfig(\n",
    "    save_checkpoints_steps=100,\n",
    "    save_summary_steps=100,\n",
    "    tf_random_seed=RANDOM_SEED,\n",
    "    #train_distribute=strategy,\n",
    "    model_dir=os.path.join(LOG_DIR, experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "test": {
      "output": "ignore",
      "timeout": 900
     }
    },
    "colab_type": "code",
    "id": "-Fhi1SjkzVBt",
    "outputId": "0fb9ef2c-073c-4ce2-cfe8-64307fdd9ddf"
   },
   "outputs": [],
   "source": [
    "estimator = adanet.Estimator(\n",
    "    head=head,\n",
    "    subnetwork_generator=SimpleCNNGenerator(\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        max_iteration_steps=max_iteration_steps,\n",
    "        seed=RANDOM_SEED),\n",
    "    max_iteration_steps=max_iteration_steps,\n",
    "    evaluator=adanet.Evaluator(\n",
    "        input_fn=input_fn(\"train\", training=False, batch_size=BATCH_SIZE),\n",
    "        steps=None),\n",
    "    adanet_loss_decay=.99,\n",
    "    config=make_config(\"simple_cnn\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, _ = tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec=tf.estimator.TrainSpec(\n",
    "        input_fn=input_fn(\"train\", training=True, batch_size=BATCH_SIZE),\n",
    "        max_steps=TRAIN_STEPS),\n",
    "    eval_spec=tf.estimator.EvalSpec(\n",
    "        input_fn=input_fn(\"test\", training=False, batch_size=BATCH_SIZE),\n",
    "        steps=None,\n",
    "        start_delay_secs=1,\n",
    "        throttle_secs=1,  \n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tJy7mKr_0jkI",
    "outputId": "b61aa3ab-ef73-443c-f78c-a0cbf71a1244"
   },
   "outputs": [],
   "source": [
    "def ensemble_architecture(result):\n",
    "    \"\"\"Extracts the ensemble architecture from evaluation results.\"\"\"\n",
    "    architecture = result[\"architecture/adanet/ensembles\"]\n",
    "    # The architecture is a serialized Summary proto for TensorBoard.\n",
    "    summary_proto = tf.summary.Summary.FromString(architecture)\n",
    "    return summary_proto.value[0].tensor.string_val[0]\n",
    "\n",
    "print(\"Accuracy:\", results[\"accuracy\"])\n",
    "print(\"Loss:\", results[\"average_loss\"])\n",
    "print(\"Architecture:\", ensemble_architecture(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only Evalute\n",
    "results= estimator.evaluate(input_fn(\"test\", training=False, batch_size=BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(results[\"loss\"])\n",
    "print(results[\"average_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(results[\"architecture/adanet/ensembles\"],\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wGtI-4_LRw1"
   },
   "source": [
    "Our `SimpleCNNGenerator` code achieves **90.21% accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EeQG9tuW4RF8"
   },
   "source": [
    "## Generating predictions on our trained model\n",
    "\n",
    "Now that we've got a trained model, we can use it to generate predictions on new input. To keep things simple, here we'll generate predictions on our `estimator` using the first 10 examples from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "test": {
      "output": "ignore",
      "timeout": 900
     }
    },
    "colab_type": "code",
    "id": "dzBtgkgm4RF8",
    "outputId": "81a11ef5-1eca-400f-f76e-1482417beafd"
   },
   "outputs": [],
   "source": [
    "predictions = estimator.predict(input_fn=input_fn(\"predict\", training=False, batch_size=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, val in enumerate(predictions):\n",
    "    predicted_class = val['class_ids'][0]\n",
    "    prediction_confidence = val['probabilities'][predicted_class] * 100\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.rcParams['figure.figsize'] = (1,1)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Predicted class: %s, confidence: %s%%' % (predicted_class, round(prediction_confidence, 3)))\n",
    "    print('Actual class: %s \\n\\n' % y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKhCzP65hGyS"
   },
   "source": [
    "## Conclusion and next steps\n",
    "\n",
    "In this tutorial, you learned how to customize `adanet` to encode your\n",
    "understanding of a particular dataset, and explore novel search spaces with\n",
    "AdaNet.\n",
    "\n",
    "One use-case that has worked for us at Google, has been to take a production\n",
    "model's TensorFlow code, convert it to into an `adanet.subnetwork.Builder`, and\n",
    "adaptively grow it into an ensemble. In many cases, this has given significant\n",
    "performance improvements.\n",
    "\n",
    "As an exercise, you can swap out the FASHION-MNIST with the MNIST handwritten\n",
    "digits dataset in this notebook using `tf.keras.datasets.mnist.load_data()`, and\n",
    "see how `SimpleCNN` performs."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "customizing_adanet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
