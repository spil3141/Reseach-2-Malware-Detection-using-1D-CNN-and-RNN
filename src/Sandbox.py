import tensorflow as tf 
from models.OneDCNNBiDLSTM import OneDCNNBiDLSTM
import numpy as np 
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

# Hyperparameters
NUM_OF_SAMPLES = 25
INPUT_SHAPE = (NUM_OF_SAMPLES, 10000000)

# Model Creation 
model = OneDCNNBiDLSTM()
# sample = tf.constant(tf.random.normal((3,1,INPUT_SHAPE[-1])), dtype=tf.float32)
# print(f"sample shape: {sample.shape}")
# print(f'output: {model(sample)}')
# model.summary() # TODO: call() function does not build the Dropout layer (training parameter)

# Dataset Creation 
x = tf.random.normal((INPUT_SHAPE), dtype=tf.float32)
y = tf.random.uniform((NUM_OF_SAMPLES, 1), minval=0, maxval= 2, dtype=tf.int32)

print(f"x shape: {x.shape}")
print(f"y shape: {y.shape}")
#  - Pre-processing 
x_train, x_test, y_train, y_test = train_test_split(x.numpy(),y.numpy(), test_size=0.17)

x_train, x_valid, y_train, y_valid = train_test_split(x_train,y_train, test_size=0.17)

def train_batch_generator():
    global x_train,y_train
    for x,y in zip(x_train,y_train):
        yield (x,y)
def valid_batch_generator():
    global x_valid,y_valid
    for x,y in zip(x_valid,y_valid):
        yield (x,y)
def test_batch_generator():
    global x_test,y_test
    for x,y in zip(x_test,y_test):
        yield (x,y)

X_train_data = tf.data.Dataset.from_generator(train_batch_generator,
                                          output_types=('float32', 'int32'),
                                          output_shapes=(tf.TensorShape((INPUT_SHAPE[-1],)), tf.TensorShape((1,)))
                                         )
X_valid_data = tf.data.Dataset.from_generator(valid_batch_generator,
                                          output_types=('float32', 'int32'),
                                          output_shapes=(tf.TensorShape((INPUT_SHAPE[-1],)), tf.TensorShape((1,)))
                                         )
X_test_data = tf.data.Dataset.from_generator(test_batch_generator,
                                          output_types=('float32', 'int32'),
                                          output_shapes=(tf.TensorShape((INPUT_SHAPE[-1],)), tf.TensorShape((1,)))
                                         )

X_train_data = X_train_data.batch(16)
X_valid_data = X_valid_data.batch(16)
X_test_data = X_test_data.batch(16)

# Compilation
def loss_func(y_true, y_pred):
    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(y_true, y_pred)

optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
model.compile(loss=loss_func, optimizer=optimizer, metrics= (tf.keras.metrics.BinaryAccuracy()))
# Training
history = model.fit(X_train_data, epochs= 10, verbose= 1, validation_data = X_valid_data )

# Evaluation 
# Getting predicted values on test dataset from model
print("prediction starts")
result = model.predict(X_test_data,verbose=1)
y_pred = [np.argmax(i) for i in result]
y_pred = np.asarray(y_pred)
print(y_pred)
# #calculate the true label for test dataset
print("y_true extraction starts")
y_true = []
for i in X_test_data.unbatch():
    y_true.append(np.argmax(i[1].numpy()))
y_true = np.asarray(y_true)
print(y_true)

# # find the confusion matrix
print("result calculation starts")
acc = accuracy_score(y_pred,y_true)
cm = confusion_matrix(y_true, y_pred)
temp = precision_recall_fscore_support(y_true, y_pred, average='weighted')
precision = temp[0]
recall = temp[1]
F1score = temp[2]


test_loss,test_accuracy  = model.evaluate(X_test_data,verbose = 1)
print(" ")
print("On Test Set: (loss,acc): %.5f %.5f" % (test_loss,test_accuracy))
# #F1score = f1_score(y_true,y_pred)
print("sklearn accuracy : {}".format(acc))
print("Precision: ", precision)
print("Recall: ", recall)
print("F1_Score: ", F1score)
print("confusion matrix:")
print("")
print(cm)
